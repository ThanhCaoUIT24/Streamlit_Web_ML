import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go # Import ƒë·ªÉ t·∫°o heatmap Plotly
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import io
import time # ƒê·ªÉ th√™m hi·ªáu ·ª©ng ch·ªù, progress bar

# --- C·∫•u h√¨nh trang ---
st.set_page_config(
    page_title="üåà‚ú® ML App Si√™u C·∫•p Vip Pro ‚ú®üåà",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="auto" # ƒê·ªÉ sidebar t·ª± ƒë·ªông ho·∫∑c 'expanded'
)

# --- CSS Si√™u C·∫•p ---
# Font Awesome CDN
st.markdown('<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css"/>', unsafe_allow_html=True)
# Google Fonts (V√≠ d·ª•: Montserrat)
st.markdown("""
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
""", unsafe_allow_html=True)

custom_css = """
<style>
    /* --- Font ch·ªØ --- */
    html, body, [class*="st-"], button, input, select, textarea {
        font-family: 'Montserrat', sans-serif;
    }

    /* --- Background Gradient --- */
    .stApp {
        /* background-image: linear-gradient(to right top, #6d327c, #485DA6, #00a1ba, #00BF98, #36C486); */
         background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
         background-size: 400% 400%;
         animation: gradientBG 15s ease infinite;
         color: #FFFFFF; /* ƒê·ªïi m√†u ch·ªØ m·∫∑c ƒë·ªãnh th√†nh tr·∫Øng cho d·ªÖ ƒë·ªçc tr√™n n·ªÅn gradient */
    }

    @keyframes gradientBG {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }

    /* --- Headers --- */
    h1, h2, h3 {
        /* font-weight: 700; */
        /* text-shadow: 2px 2px 4px rgba(0,0,0,0.2); */
         color: #ffffff; /* M√†u tr·∫Øng n·ªïi b·∫≠t tr√™n n·ªÅn gradient */
         font-weight: 700; /* Ch·ªØ ƒë·∫≠m h∆°n */
         text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); /* ƒê·ªï b√≥ng nh·∫π */
    }
     h1 {
         font-size: 2.8em; /* TƒÉng k√≠ch th∆∞·ªõc ti√™u ƒë·ªÅ ch√≠nh */
         text-align: center;
         margin-bottom: 20px;
     }
     h2 { font-size: 2em; border-bottom: 2px solid rgba(255,255,255,0.5); padding-bottom: 5px; margin-top: 30px;}
     h3 { font-size: 1.5em; color: #f0f0f0;}


    /* --- N√∫t b·∫•m n·ªïi b·∫≠t --- */
    .stButton>button {
        border: none; /* B·ªè vi·ªÅn m·∫∑c ƒë·ªãnh */
        border-radius: 25px; /* Bo tr√≤n nhi·ªÅu h∆°n */
        padding: 12px 28px; /* TƒÉng padding */
        font-size: 16px;
        font-weight: 600; /* ƒê·∫≠m v·ª´a */
        color: white;
        background-image: linear-gradient(to right, #fc5c7d, #6a82fb, #fc5c7d); /* Gradient cho n√∫t */
        background-size: 200% auto; /* K√≠ch th∆∞·ªõc gradient ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng chuy·ªÉn ƒë·ªông */
        transition: 0.5s; /* Hi·ªáu ·ª©ng chuy·ªÉn m√†u m∆∞·ª£t */
        box-shadow: 0 4px 15px 0 rgba(116, 79, 168, 0.75); /* ƒê·ªï b√≥ng */
        margin-top: 10px; /* Kho·∫£ng c√°ch tr√™n */
    }
    .stButton>button:hover {
        background-position: right center; /* Chuy·ªÉn gradient khi hover */
        color: #fff;
        text-decoration: none;
        box-shadow: 0 6px 20px 0 rgba(116, 79, 168, 0.9); /* B√≥ng ƒë·∫≠m h∆°n khi hover */
        transform: translateY(-2px); /* N√¢ng n√∫t l√™n nh·∫π */
    }
     .stButton>button:active {
        transform: translateY(0px); /* H·∫° n√∫t xu·ªëng khi nh·∫•n */
        box-shadow: 0 4px 15px 0 rgba(116, 79, 168, 0.75);
     }

    /* --- Styling cho Selectbox, Multiselect, NumberInput --- */
    /* (Vi·ªác style s√¢u c√°c widget c·ªßa Streamlit c√≥ th·ªÉ ph·ª©c t·∫°p v√† d·ªÖ b·ªã l·ªói khi c·∫≠p nh·∫≠t) */
    div[data-baseweb="select"] > div,
    div[data-baseweb="input"] > div,
    div[data-testid="stMultiSelect"] > div {
        background-color: rgba(255, 255, 255, 0.1); /* N·ªÅn h∆°i trong su·ªët */
        border-radius: 8px;
        border: 1px solid rgba(255, 255, 255, 0.3);
    }
     div[data-baseweb="select"] > div:hover,
     div[data-baseweb="input"] > div:hover,
     div[data-testid="stMultiSelect"] > div:hover {
         border: 1px solid rgba(255, 255, 255, 0.7);
     }
    /* M√†u ch·ªØ cho input/select */
     /* .stTextInput input, .stNumberInput input, div[data-baseweb="select"] { color: #FFFFFF !important; } */


    /* --- Tabs --- */
    .stTabs [data-baseweb="tab-list"] {
        gap: 30px; /* Kho·∫£ng c√°ch l·ªõn h∆°n gi·ªØa c√°c tab */
        justify-content: center; /* CƒÉn gi·ªØa c√°c tab */
        border-bottom: 2px solid rgba(255,255,255,0.2); /* ƒê∆∞·ªùng k·∫ª d∆∞·ªõi tab list */
    }
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        white-space: pre-wrap;
        background-color: transparent;
        border-radius: 10px 10px 0 0; /* Bo g√≥c tr√™n */
        gap: 10px;
        padding: 15px 25px;
        color: rgba(255, 255, 255, 0.7); /* M√†u ch·ªØ tab kh√¥ng active nh·∫°t h∆°n */
        font-weight: 600;
        font-size: 1.1em;
        transition: all 0.3s ease;
        border: none; /* B·ªè vi·ªÅn m·∫∑c ƒë·ªãnh */
    }
    .stTabs [aria-selected="true"] {
        background-image: linear-gradient(to top, rgba(255,255,255,0.15), rgba(255,255,255,0.0)); /* Gradient nh·∫π cho tab active */
        color: white !important; /* M√†u ch·ªØ tr·∫Øng r√µ r√†ng */
        border-bottom: 3px solid #FFFFFF; /* ƒê∆∞·ªùng k·∫ª d∆∞·ªõi tab active */
    }
    .stTabs [data-baseweb="tab"]:hover {
        background-color: rgba(255, 255, 255, 0.1);
        color: white;
    }

    /* --- Card Style cho Expander --- */
    .stExpander {
        border: none; /* B·ªè vi·ªÅn m·∫∑c ƒë·ªãnh */
        background-color: rgba(255, 255, 255, 0.1); /* N·ªÅn m·ªù */
        backdrop-filter: blur(5px); /* Hi·ªáu ·ª©ng k√≠nh m·ªù */
        border-radius: 10px; /* Bo g√≥c */
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        margin-bottom: 15px; /* Kho·∫£ng c√°ch d∆∞·ªõi */
        overflow: hidden; /* ƒê·∫£m b·∫£o n·ªôi dung kh√¥ng tr√†n ra ngo√†i */
    }
    .stExpander header {
        font-weight: 600;
        color: #FFFFFF; /* Ch·ªØ ti√™u ƒë·ªÅ expander m√†u tr·∫Øng */
        background-color: rgba(0, 0, 0, 0.1); /* N·ªÅn nh·∫π cho header expander */
        padding: 10px 15px !important;
        border-radius: 10px 10px 0 0;
    }
     .stExpander header:hover {
         background-color: rgba(0, 0, 0, 0.2);
     }
    .stExpander > div[role="button"] > div > svg {
         fill: #FFFFFF; /* M√†u icon m≈©i t√™n tr·∫Øng */
     }
     .streamlit-expanderContent {
         padding: 15px; /* Padding cho n·ªôi dung b√™n trong expander */
         color: #e0e0e0; /* M√†u ch·ªØ n·ªôi dung b√™n trong */
     }

    /* --- Styling cho DataFrame --- */
     .stDataFrame {
         border: 1px solid rgba(255, 255, 255, 0.2);
         border-radius: 8px;
         /* background-color: rgba(0, 0, 0, 0.1); */
     }
     /* Header c·ªßa dataframe */
     /* .stDataFrame th {
         background-color: rgba(255, 255, 255, 0.15);
         color: white;
         font-weight: bold;
     } */
     /* Cell c·ªßa dataframe */
     /* .stDataFrame td {
         color: #e0e0e0;
     } */


    /* --- Metrics --- */
     div[data-testid="stMetric"] {
         background-color: rgba(255, 255, 255, 0.1);
         border: 1px solid rgba(255, 255, 255, 0.3);
         padding: 15px 20px;
         border-radius: 10px;
         box-shadow: 0 4px 10px rgba(0,0,0,0.1);
         text-align: center;
     }
     div[data-testid="stMetricLabel"] {
         font-weight: bold;
         color: #f0f0f0; /* M√†u label */
     }
     div[data-testid="stMetricValue"] {
         font-size: 2.2em; /* Gi√° tr·ªã to h∆°n */
         font-weight: 700;
         color: #FFFFFF; /* Gi√° tr·ªã m√†u tr·∫Øng */
     }
     div[data-testid="stMetricDelta"] { /* Ch·ªâ s·ªë thay ƒë·ªïi (delta) */
        font-weight: normal;
        color: #a0a4b8 !important;
     }
     div[data-testid="stMetric"] > div > div:last-child > div { /* Ph·∫ßn caption (ghi ch√∫) */
         color: #cccccc !important;
         font-style: italic;
     }

    /* --- Input Forms --- */
     div[data-testid="stForm"] {
         border: 1px dashed rgba(255, 255, 255, 0.3);
         border-radius: 10px;
         padding: 20px;
         background-color: rgba(0, 0, 0, 0.1);
     }


     /* --- Sidebar (n·∫øu d√πng) --- */
     section[data-testid="stSidebar"] > div:first-child {
         background-image: linear-gradient(to bottom, #485DA6, #00a1ba); /* Gradient cho sidebar */
     }

    /* === CSS HEADER & Lo·∫°i b·ªè vi·ªÅn l·∫° === */

    /* Lo·∫°i b·ªè margin/padding/border c·ªßa body ƒë·ªÉ tr√°nh vi·ªÅn l·∫° */
    body {
        margin: 0 !important;
        padding: 0 !important;
        border: none !important;
        /* overflow-x: hidden; */ /* Th·ª≠ th√™m n·∫øu c√≥ thanh cu·ªôn ngang l·∫° */
    }

    /* Target thanh header ch√≠nh */
    header[data-testid="stHeader"] {
        background-image: none !important;
        background-color: #0E1117 !important; /* Gi·ªØ m√†u n·ªÅn t·ªëi */
        border: none !important; /* X√≥a border */
        margin: 0 !important; /* X√≥a margin */
        padding: 0 !important; /* X√≥a padding */
        box-shadow: none !important; /* X√≥a shadow n·∫øu c√≥ */
    }

    /* Target d·∫£i m√†u trang tr√≠ */
    div[data-testid="stDecoration"] {
        background-image: none !important;
        background-color: #0E1117 !important; /* ƒê·ªìng b·ªô m√†u n·ªÅn t·ªëi */
        border: none !important; /* X√≥a border */
        margin: 0 !important; /* X√≥a margin */
        padding: 0 !important; /* X√≥a padding */
        box-shadow: none !important; /* X√≥a shadow n·∫øu c√≥ */
        height: 5px !important; /* ƒê·∫∑t chi·ªÅu cao c·ªë ƒë·ªãnh nh·ªè cho n√≥, ho·∫∑c th·ª≠ display: none */
        /* display: none !important; */ /* B·ªè comment ƒë·ªÉ ·∫©n ho√†n to√†n n·∫øu c·∫ßn */
    }

    /* ƒê·∫£m b·∫£o c√°c icon/link tr√™n toolbar v·∫´n m√†u tr·∫Øng */
     header [data-testid="stToolbar"] button svg,
     header [data-testid="stToolbar"] button span,
     div[data-testid="stMainMenu"] button svg,
     header [data-testid="stToolbar"] a svg,
     header [data-testid="stToolbar"] a {
         fill: #FFFFFF !important;
         color: #FFFFFF !important;
     }

</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- C√°c h√†m tr·ª£ gi√∫p (Gi·ªØ nguy√™n logic, ch·ªâ thay ƒë·ªïi plot) ---
@st.cache_data # S·ª≠ d·ª•ng cache_data cho data loading
def load_data(uploaded_file):
    """T·∫£i d·ªØ li·ªáu t·ª´ t·ªáp CSV ƒë∆∞·ª£c t·∫£i l√™n."""
    try:
        df = pd.read_csv(uploaded_file)
        return df
    except Exception as e:
        # Tr·∫£ v·ªÅ l·ªói ƒë·ªÉ c√≥ th·ªÉ hi·ªÉn th·ªã trong lu·ªìng ch√≠nh
        return f"L·ªói khi ƒë·ªçc t·ªáp CSV: {e}"

# H√†m ti·ªÅn x·ª≠ l√Ω (Gi·ªØ nguy√™n logic c·ªët l√µi)
def preprocess_data(df, target_column, selected_features):
    """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: ch·ªçn c·ªôt, x·ª≠ l√Ω NaN, one-hot encode, scale."""
    if not selected_features:
        return "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt feature.", None, None, None, None, None, None, None # Th√™m None cho imputer v√† features
    if not target_column:
         return "Vui l√≤ng ch·ªçn c·ªôt target.", None, None, None, None, None, None, None
    if target_column not in df.columns:
        return f"C·ªôt target '{target_column}' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.", None, None, None, None, None, None, None
    if not all(feature in df.columns for feature in selected_features):
         missing_features = [f for f in selected_features if f not in df.columns]
         return f"C√°c feature sau kh√¥ng t·ªìn t·∫°i: {', '.join(missing_features)}.", None, None, None, None, None, None, None

    df_subset = df[selected_features + [target_column]].copy()

    # Ki·ªÉm tra xem target c√≥ ph·∫£i d·∫°ng s·ªë kh√¥ng (n·∫øu d√πng cho h·ªìi quy)
    if df_subset[target_column].dtype not in [np.number]:
        is_binary_after_potential_get_dummies = False
        if not is_binary_after_potential_get_dummies:
            return f"C·ªôt target '{target_column}' ph·∫£i l√† d·∫°ng s·ªë cho m√¥ h√¨nh h·ªìi quy.", None, None, None, None, None, None, None


    numeric_cols = df_subset.select_dtypes(include=np.number).columns.tolist()
    categorical_cols = df_subset.select_dtypes(exclude=np.number).columns.tolist()

    # X√°c ƒë·ªãnh c·ªôt g·ªëc tr∆∞·ªõc khi x·ª≠ l√Ω NaN
    original_numeric_features = [col for col in numeric_cols if col != target_column and col in selected_features]
    original_categorical_features = [col for col in categorical_cols if col != target_column and col in selected_features] # Ch·ªâ l·∫•y c√°c c·ªôt ƒë∆∞·ª£c ch·ªçn

    # X·ª≠ l√Ω NaN cho target tr∆∞·ªõc ti√™n
    df_subset.dropna(subset=[target_column], inplace=True)
    if df_subset.empty:
        return "Kh√¥ng c√≤n d·ªØ li·ªáu sau khi lo·∫°i b·ªè NaN ·ªü c·ªôt target.", None, None, None, None, None, None, None

    # --- S·ª¨A L·ªñI IMUTER ---
    # Kh·ªüi t·∫°o imputers
    numeric_imputer = SimpleImputer(strategy='mean')
    categorical_imputer = SimpleImputer(strategy='most_frequent')

    # FIT imputer LU√îN LU√îN tr√™n c√°c c·ªôt ƒë√£ ch·ªçn (n·∫øu c√≥) ƒë·ªÉ ƒë·∫£m b·∫£o n√≥ ƒë∆∞·ª£c fitted
    # Ngay c·∫£ khi kh√¥ng c√≥ NaN trong t·∫≠p d·ªØ li·ªáu hi·ªán t·∫°i, n√≥ c·∫ßn ƒë∆∞·ª£c fit ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
    if original_numeric_features:
        numeric_imputer.fit(df_subset[original_numeric_features])
        # Ch·ªâ TRANSFORM n·∫øu th·ª±c s·ª± c√≥ NaN
        if df_subset[original_numeric_features].isnull().any().any():
            df_subset[original_numeric_features] = numeric_imputer.transform(df_subset[original_numeric_features])
    else:
        # N·∫øu kh√¥ng c√≥ c·ªôt s·ªë n√†o ƒë∆∞·ª£c ch·ªçn, fit imputer tr√™n m·ªôt m·∫£ng tr·ªëng ƒë·ªÉ tr√°nh l·ªói NotFittedError
        # M·∫∑c d√π n√≥ s·∫Ω kh√¥ng l√†m g√¨, nh∆∞ng n√≥ s·∫Ω ·ªü tr·∫°ng th√°i "fitted"
        numeric_imputer.fit(np.empty((0, 0)))


    if original_categorical_features:
        categorical_imputer.fit(df_subset[original_categorical_features])
        # Ch·ªâ TRANSFORM n·∫øu th·ª±c s·ª± c√≥ NaN
        if df_subset[original_categorical_features].isnull().any().any():
            df_subset[original_categorical_features] = categorical_imputer.transform(df_subset[original_categorical_features])
    else:
         # Fit tr√™n m·∫£ng tr·ªëng n·∫øu kh√¥ng c√≥ c·ªôt category
        categorical_imputer.fit(np.empty((0, 0), dtype=object))
    # --- K·∫æT TH√öC S·ª¨A L·ªñI ---


    # One-Hot Encoding cho c√°c c·ªôt category g·ªëc ƒê√É CH·ªåN
    df_processed = pd.get_dummies(df_subset, columns=original_categorical_features, drop_first=True)

    # T√°ch X, y sau khi encoding
    if target_column in original_categorical_features:
        st.warning(f"C·ªôt target '{target_column}' l√† d·∫°ng category. ƒêang c·ªë g·∫Øng t√¨m c·ªôt sau one-hot encoding.")
        possible_target_cols = [col for col in df_processed.columns if col.startswith(target_column + "_")]
        if len(possible_target_cols) > 0:
             target_column_processed = possible_target_cols[0]
             st.info(f"S·ª≠ d·ª•ng '{target_column_processed}' l√†m target sau encoding.")
             y = df_processed[target_column_processed]
             cols_to_drop = [target_column] + possible_target_cols
             X = df_processed.drop(columns=cols_to_drop, errors='ignore')
        else:
             return f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh c·ªôt target '{target_column}' sau khi m√£ h√≥a.", None, None, None, None, None, None, None
    elif target_column in df_processed.columns:
        y = df_processed[target_column]
        X = df_processed.drop(target_column, axis=1)
    else:
         return f"Kh√¥ng t√¨m th·∫•y c·ªôt target '{target_column}' trong d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω.", None, None, None, None, None, None, None


    feature_names_processed = X.columns.tolist() # L·∫•y t√™n c√°c c·ªôt feature sau khi x·ª≠ l√Ω

    if X.empty or len(feature_names_processed) == 0:
        # Tr·∫£ v·ªÅ ƒë·ªß c√°c gi√° tr·ªã None
        return "Kh√¥ng c√≤n feature n√†o sau khi ti·ªÅn x·ª≠ l√Ω.", None, None, None, numeric_imputer, categorical_imputer, original_numeric_features, original_categorical_features

    # Chu·∫©n h√≥a ch·ªâ c√°c c·ªôt features (X)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Tr·∫£ v·ªÅ c√°c ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c FIT (scaler, imputers)
    return X_scaled, y, feature_names_processed, scaler, numeric_imputer, categorical_imputer, original_numeric_features, original_categorical_features


# H√†m hu·∫•n luy·ªán (Th√™m progress bar)
def train_model(X_train, y_train, model_name, params):
    """Hu·∫•n luy·ªán m√¥ h√¨nh ƒë√£ ch·ªçn v·ªõi c√°c tham s·ªë."""
    model = None
    model_display_name = model_name # Gi·ªØ t√™n g·ªëc ƒë·ªÉ hi·ªÉn th·ªã

    try:
        if model_name == "Linear Regression":
            model = LinearRegression()
        elif model_name == "Random Forest Regressor":
            # L·∫•y tham s·ªë v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh an to√†n
            n_estimators = params.get('n_estimators', 100)
            max_depth = params.get('max_depth', None)
            model = RandomForestRegressor(
                n_estimators=n_estimators if n_estimators > 0 else 100, # ƒê·∫£m b·∫£o > 0
                max_depth=max_depth if max_depth is None or max_depth >= 0 else None, # None ho·∫∑c >= 0
                random_state=42,
                n_jobs=-1
            )
        elif model_name == "Support Vector Regressor (SVR)":
             # L·∫•y tham s·ªë v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh an to√†n
            C = params.get('C', 1.0)
            epsilon = params.get('epsilon', 0.1)
            kernel = params.get('kernel', 'rbf')
            model = SVR(
                C=C if C > 0 else 1.0, # ƒê·∫£m b·∫£o > 0
                epsilon=epsilon if epsilon > 0 else 0.1, # ƒê·∫£m b·∫£o > 0
                kernel=kernel if kernel in ['rbf', 'linear', 'poly', 'sigmoid'] else 'rbf'
            )
        else:
            st.error(f"T√™n m√¥ h√¨nh kh√¥ng h·ª£p l·ªá: {model_name}")
            return None, "M√¥ h√¨nh kh√¥ng h·ª£p l·ªá"

        # --- Th√™m Progress Bar ---
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text(f"‚è≥ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán {model_display_name}...")

        start_time = time.time()
        model.fit(X_train, y_train)
        end_time = time.time()
        training_time = end_time - start_time

        # C·∫≠p nh·∫≠t progress bar v√† status
        for i in range(100):
            time.sleep(0.005) # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω nh·ªè
            progress_bar.progress(i + 1)

        status_text.success(f"‚úÖ Ho√†n th√†nh hu·∫•n luy·ªán {model_display_name} trong {training_time:.2f} gi√¢y!")
        time.sleep(1) # Ch·ªù 1 gi√¢y ƒë·ªÉ user th·∫•y th√¥ng b√°o success
        status_text.empty() # X√≥a th√¥ng b√°o text
        progress_bar.empty() # X√≥a progress bar

        return model, None # Tr·∫£ v·ªÅ model v√† kh√¥ng c√≥ l·ªói

    except Exception as e:
        error_message = f"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh {model_display_name}: {e}"
        st.error(error_message)
        # ƒê·∫£m b·∫£o x√≥a progress bar v√† status text n·∫øu l·ªói x·∫£y ra gi·ªØa ch·ª´ng
        if 'progress_bar' in locals() and progress_bar is not None: progress_bar.empty()
        if 'status_text' in locals() and status_text is not None: status_text.empty()
        return None, error_message # Tr·∫£ v·ªÅ kh√¥ng c√≥ model v√† th√¥ng b√°o l·ªói

# --- Kh·ªüi t·∫°o Session State (Th√™m c√°c m·ª•c c·∫ßn thi·∫øt) ---
if 'model' not in st.session_state: st.session_state.model = None
if 'scaler' not in st.session_state: st.session_state.scaler = None
if 'numeric_imputer' not in st.session_state: st.session_state.numeric_imputer = None
if 'categorical_imputer' not in st.session_state: st.session_state.categorical_imputer = None
if 'feature_names_processed' not in st.session_state: st.session_state.feature_names_processed = None # T√™n feature SAU ti·ªÅn x·ª≠ l√Ω
if 'target_column' not in st.session_state: st.session_state.target_column = None
if 'numeric_cols_original' not in st.session_state: st.session_state.numeric_cols_original = None # T√™n feature s·ªë G·ªêC
if 'categorical_cols_original' not in st.session_state: st.session_state.categorical_cols_original = None # T√™n feature category G·ªêC
if 'df_loaded' not in st.session_state: st.session_state.df_loaded = False
if 'df' not in st.session_state: st.session_state.df = None # DataFrame g·ªëc
if 'uploaded_filename' not in st.session_state: st.session_state.uploaded_filename = None
if 'preprocessing_error' not in st.session_state: st.session_state.preprocessing_error = None # L∆∞u l·ªói ti·ªÅn x·ª≠ l√Ω
if 'training_error' not in st.session_state: st.session_state.training_error = None # L∆∞u l·ªói hu·∫•n luy·ªán
if 'last_prediction' not in st.session_state: st.session_state.last_prediction = None # L∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n cu·ªëi

# --- Giao di·ªán ng∆∞·ªùi d√πng v·ªõi Tabs v√† Style M·ªõi ---
st.title("üöÄ ·ª®ng d·ª•ng Machine Learning Si√™u C·∫•p Vip Pro üöÄ")
st.markdown("---", unsafe_allow_html=True) # D√πng HTML ƒë·ªÉ ƒë∆∞·ªùng k·∫ª c√≥ th·ªÉ ƒë∆∞·ª£c style n·∫øu mu·ªën

# Lo·∫°i b·ªè th·∫ª <i> kh·ªèi t√™n tab, c√≥ th·ªÉ d√πng emoji thay th·∫ø
tab1, tab2, tab3 = st.tabs([
    "**üìä T·∫£i & Kh√°m ph√° D·ªØ li·ªáu**", # Thay icon b·∫±ng emoji ho·∫∑c b·ªè ƒëi
    "**‚öôÔ∏è Hu·∫•n luy·ªán M√¥ h√¨nh**",
    "**‚ú® D·ª± ƒëo√°n K·∫øt qu·∫£**"
])

# == Tab 1: T·∫£i d·ªØ li·ªáu v√† EDA ==
with tab1:
    upload_container = st.container()
    with upload_container:
        st.markdown("### <i class='fas fa-file-csv'></i> 1. T·∫£i l√™n t·ªáp CSV c·ªßa b·∫°n", unsafe_allow_html=True)
        uploaded_file = st.file_uploader(
            "K√©o th·∫£ ho·∫∑c ch·ªçn t·ªáp...",
            type="csv", # Ch·ªâ ch·∫•p nh·∫≠n file .csv
            label_visibility="collapsed"
        )

    if uploaded_file is not None:
        # Ch·ªâ load l·∫°i n·∫øu ch∆∞a load ho·∫∑c t√™n file kh√°c
        if not st.session_state.df_loaded or st.session_state.uploaded_filename != uploaded_file.name:
            with st.spinner("üîÑ ƒêang t·∫£i v√† ki·ªÉm tra t·ªáp..."):
                # Reset tr·∫°ng th√°i tr∆∞·ªõc khi load file m·ªõi
                st.session_state.df = None
                st.session_state.df_loaded = False
                st.session_state.model = None
                st.session_state.scaler = None
                st.session_state.numeric_imputer = None
                st.session_state.categorical_imputer = None
                st.session_state.feature_names_processed = None
                st.session_state.numeric_cols_original = None
                st.session_state.categorical_cols_original = None
                st.session_state.target_column = None
                st.session_state.preprocessing_error = None
                st.session_state.training_error = None
                st.session_state.last_prediction = None
                st.session_state.uploaded_filename = uploaded_file.name

                result = load_data(uploaded_file)
                if isinstance(result, pd.DataFrame):
                    st.session_state.df = result
                    st.session_state.df_loaded = True
                    st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng t·ªáp: **{st.session_state.uploaded_filename}**")
                    # Kh√¥ng c·∫ßn rerun ·ªü ƒë√¢y n·ªØa, s·∫Ω t·ª± ch·∫°y xu·ªëng d∆∞·ªõi
                else: # N·∫øu load_data tr·∫£ v·ªÅ l·ªói (string)
                    st.error(result) # Hi·ªÉn th·ªã l·ªói load_data
                    st.session_state.uploaded_filename = None # Reset t√™n file n·∫øu l·ªói
                    st.session_state.df_loaded = False
            # st.rerun() # Kh√¥ng c·∫ßn rerun, ƒë·ªÉ code ch·∫°y ti·∫øp xu·ªëng ph·∫ßn EDA n·∫øu th√†nh c√¥ng

    # Ch·ªâ hi·ªÉn th·ªã EDA n·∫øu ƒë√£ load th√†nh c√¥ng
    if st.session_state.df_loaded and st.session_state.df is not None:
        df = st.session_state.df

        st.markdown("### <i class='fas fa-search'></i> 2. Kh√°m ph√° D·ªØ li·ªáu (EDA)", unsafe_allow_html=True)

        with st.expander("üìä Xem tr∆∞·ªõc d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu)", expanded=False):
            st.dataframe(df.head())

        col_info1, col_info2, col_info3 = st.columns([1,1,1])
        with col_info1:
            with st.expander("‚ÑπÔ∏è Th√¥ng tin chung", expanded=False):
                st.write(f"**D√≤ng:** {df.shape[0]}, **C·ªôt:** {df.shape[1]}")
                buffer = io.StringIO()
                df.info(buf=buffer)
                s = buffer.getvalue()
                st.code(s, language=None) # language=None ƒë·ªÉ kh√¥ng c·ªë highlight c√∫ ph√°p
        with col_info2:
            with st.expander("üî¢ Th·ªëng k√™ m√¥ t·∫£ (S·ªë)", expanded=False):
                try:
                    st.dataframe(df.describe(include=np.number))
                except Exception:
                    st.info("Kh√¥ng c√≥ c·ªôt s·ªë.")
        with col_info3:
            with st.expander("‚ùì Gi√° tr·ªã thi·∫øu (NaN)", expanded=False):
                missing_values = df.isnull().sum()
                missing_df = pd.DataFrame({'C·ªôt': missing_values.index, 'S·ªë l∆∞·ª£ng NaN': missing_values.values})
                missing_df = missing_df[missing_df['S·ªë l∆∞·ª£ng NaN'] > 0].sort_values(by='S·ªë l∆∞·ª£ng NaN', ascending=False)
                if not missing_df.empty:
                    st.dataframe(missing_df)
                    st.warning(f"T√¨m th·∫•y **{missing_df['S·ªë l∆∞·ª£ng NaN'].sum()}** gi√° tr·ªã thi·∫øu.")
                else:
                    st.success("üéâ Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu!")

        st.markdown("### <i class='fas fa-chart-bar'></i> 3. Tr·ª±c quan h√≥a D·ªØ li·ªáu", unsafe_allow_html=True)
        numeric_columns = df.select_dtypes(include=np.number).columns.tolist()
        categorical_columns = df.select_dtypes(exclude=np.number).columns.tolist()

        if not numeric_columns and not categorical_columns:
             st.warning("‚ö†Ô∏è Kh√¥ng c√≥ c·ªôt d·ªØ li·ªáu n√†o ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        else:
            col_plot_select, col_plot_display = st.columns([0.3, 0.7], gap="large")

            with col_plot_select:
                plot_options = []
                if numeric_columns:
                    plot_options.extend(["Histogram", "Box Plot", "Heatmap T∆∞∆°ng quan"])
                if len(numeric_columns) >= 2:
                     plot_options.append("Scatter Plot")
                # Th√™m c√°c plot cho category n·∫øu mu·ªën (v√≠ d·ª•: Count Plot)
                # if categorical_columns:
                #     plot_options.append("Count Plot")

                if not plot_options:
                     st.info("Kh√¥ng ƒë·ªß lo·∫°i c·ªôt ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
                else:
                    plot_type = st.selectbox(
                        "Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì:",
                        plot_options,
                        key="plot_type_select"
                    )

                    # Ch·ªçn c·ªôt cho t·ª´ng lo·∫°i plot
                    selected_col_hist_box = None
                    selected_col_scatter_x = None
                    selected_col_scatter_y = None
                    selected_col_scatter_hue = None

                    if plot_type in ["Histogram", "Box Plot"] and numeric_columns:
                        selected_col_hist_box = st.selectbox("Ch·ªçn c·ªôt s·ªë:", numeric_columns, key="hist_box_col")
                    elif plot_type == "Scatter Plot" and len(numeric_columns) >= 2:
                        selected_col_scatter_x = st.selectbox("Ch·ªçn c·ªôt X:", numeric_columns, key="scatter_x", index=0)
                        col2_options = [col for col in numeric_columns if col != selected_col_scatter_x]
                        if col2_options: # ƒê·∫£m b·∫£o c√≥ c·ªôt Y ƒë·ªÉ ch·ªçn
                             selected_col_scatter_y = st.selectbox("Ch·ªçn c·ªôt Y:", col2_options, key="scatter_y", index=min(1, len(col2_options)-1))
                             # Cho ph√©p ch·ªçn c·ªôt category ho·∫∑c numeric ƒë·ªÉ t√¥ m√†u
                             hue_options = [None] + numeric_columns + categorical_columns
                             # Lo·∫°i b·ªè c√°c c·ªôt ƒë√£ ch·ªçn cho X, Y kh·ªèi hue options n·∫øu ch√∫ng t·ªìn t·∫°i
                             hue_options = [opt for opt in hue_options if opt != selected_col_scatter_x and opt != selected_col_scatter_y]
                             selected_col_scatter_hue = st.selectbox("Ph√¢n m√†u theo (T√πy ch·ªçn):", hue_options, key="scatter_hue", index=0) # M·∫∑c ƒë·ªãnh l√† None
                        else:
                             st.warning("C·∫ßn √≠t nh·∫•t 2 c·ªôt s·ªë kh√°c nhau.")
                             plot_type = None # V√¥ hi·ªáu h√≥a plot n·∫øu kh√¥ng ƒë·ªß c·ªôt
                    # Heatmap kh√¥ng c·∫ßn ch·ªçn c·ªôt th√™m

            with col_plot_display:
                # T·∫°o v√† hi·ªÉn th·ªã bi·ªÉu ƒë·ªì Plotly
                try: # B·ªçc trong try-except ƒë·ªÉ b·∫Øt l·ªói v·∫Ω bi·ªÉu ƒë·ªì
                    if plot_type == "Histogram" and selected_col_hist_box:
                        fig = px.histogram(
                            df,
                            x=selected_col_hist_box,
                            marginal="box", # Th√™m box plot ·ªü tr√™n
                            title=f"<b>Ph√¢n ph·ªëi c·ªßa {selected_col_hist_box}</b>",
                            opacity=0.8,
                            color_discrete_sequence=px.colors.qualitative.Vivid # B·∫£ng m√†u s·∫∑c s·ª°
                        )
                        fig.update_layout(bargap=0.1, title_x=0.5, xaxis_title=selected_col_hist_box, yaxis_title="S·ªë l∆∞·ª£ng")
                        st.plotly_chart(fig, use_container_width=True)

                    elif plot_type == "Box Plot" and selected_col_hist_box:
                        fig = px.box(
                            df,
                            y=selected_col_hist_box,
                            title=f"<b>Bi·ªÉu ƒë·ªì Box Plot c·ªßa {selected_col_hist_box}</b>",
                            points="all", # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c ƒëi·ªÉm
                            color_discrete_sequence=px.colors.qualitative.Pastel
                        )
                        fig.update_layout(title_x=0.5)
                        st.plotly_chart(fig, use_container_width=True)

                    elif plot_type == "Scatter Plot" and selected_col_scatter_x and selected_col_scatter_y:
                        fig = px.scatter(
                            df,
                            x=selected_col_scatter_x,
                            y=selected_col_scatter_y,
                            color=selected_col_scatter_hue,
                            title=f"<b>M·ªëi quan h·ªá gi·ªØa {selected_col_scatter_x} v√† {selected_col_scatter_y}</b>",
                            opacity=0.7,
                            color_continuous_scale=px.colors.sequential.Viridis if selected_col_scatter_hue and df[selected_col_scatter_hue].dtype in [np.int64, np.float64] else None, # Scale m√†u n·∫øu c·ªôt m√†u l√† s·ªë
                            color_discrete_sequence=px.colors.qualitative.Bold if selected_col_scatter_hue and df[selected_col_scatter_hue].dtype not in [np.int64, np.float64] else px.colors.qualitative.Plotly # Scale m√†u n·∫øu c·ªôt m√†u l√† category
                        )
                        fig.update_layout(title_x=0.5, xaxis_title=selected_col_scatter_x, yaxis_title=selected_col_scatter_y)
                        st.plotly_chart(fig, use_container_width=True)

                    elif plot_type == "Heatmap T∆∞∆°ng quan":
                        if len(numeric_columns) > 1:
                            # Ch·ªâ t√≠nh corr tr√™n c·ªôt s·ªë, x·ª≠ l√Ω NaN tr∆∞·ªõc khi t√≠nh corr
                            corr = df[numeric_columns].dropna().corr()
                            fig = go.Figure(data=go.Heatmap(
                                    z=corr.values,
                                    x=corr.columns,
                                    y=corr.columns,
                                    colorscale='RdBu', # B·∫£ng m√†u ƒë·ªè-xanh d∆∞∆°ng
                                    zmin=-1, zmax=1, # Chu·∫©n h√≥a thang m√†u
                                    text=corr.values, # Hi·ªÉn th·ªã gi√° tr·ªã
                                    texttemplate="%{text:.2f}", # ƒê·ªãnh d·∫°ng gi√° tr·ªã
                                    hoverongaps = False))
                            fig.update_layout(
                                title='<b>Ma tr·∫≠n T∆∞∆°ng quan Heatmap (C·ªôt s·ªë)</b>',
                                xaxis_tickangle=-45,
                                title_x=0.5,
                                height=max(400, len(numeric_columns) * 30) # ƒêi·ªÅu ch·ªânh chi·ªÅu cao
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            st.caption("Gi√° tr·ªã t·ª´ -1 ƒë·∫øn 1. G·∫ßn 1: T∆∞∆°ng quan d∆∞∆°ng m·∫°nh, G·∫ßn -1: T∆∞∆°ng quan √¢m m·∫°nh, G·∫ßn 0: √çt t∆∞∆°ng quan tuy·∫øn t√≠nh.")
                        else:
                             st.warning("C·∫ßn √≠t nh·∫•t 2 c·ªôt s·ªë ƒë·ªÉ v·∫Ω heatmap t∆∞∆°ng quan.")
                except Exception as plot_error:
                     st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {plot_error}")


    elif not uploaded_file: # Ch·ªâ hi·ªÉn th·ªã n·∫øu ch∆∞a upload file g√¨
        st.info("üëã Ch√†o m·ª´ng! H√£y t·∫£i l√™n m·ªôt t·ªáp CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu h√†nh tr√¨nh kh√°m ph√° d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh.")
        # C√≥ th·ªÉ th√™m Lottie animation ·ªü ƒë√¢y
        # try:
        #     import requests
        #     from streamlit_lottie import st_lottie
        #     # V√≠ d·ª•: animation t·ª´ lottiefiles.com
        #     # response = requests.get("URL_TO_LOTTIE_JSON")
        #     # lottie_json = response.json()
        #     # st_lottie(lottie_json, speed=1, reverse=False, loop=True, quality="low", height=300, key="lottie_hello")
        # except ImportError:
        #      st.write("C√†i ƒë·∫∑t streamlit-lottie ƒë·ªÉ hi·ªÉn th·ªã animation: pip install streamlit-lottie")
        # except Exception as e:
        #      st.write(f"Kh√¥ng th·ªÉ t·∫£i animation: {e}")

# == Tab 2: Hu·∫•n luy·ªán M√¥ h√¨nh ==
with tab2:
    st.markdown("### <i class='fas fa-tasks'></i> 3. Ch·ªçn Features, Target & M√¥ h√¨nh", unsafe_allow_html=True)

    if st.session_state.df_loaded and st.session_state.df is not None:
        df = st.session_state.df

        col1_setup, col2_setup = st.columns(2, gap="large")

        with col1_setup:
            st.markdown("#### <i class='fas fa-bullseye'></i> Features & Target", unsafe_allow_html=True)
            all_columns = df.columns.tolist()
            # Cho ph√©p ch·ªçn b·∫•t k·ª≥ c·ªôt s·ªë n√†o l√†m target
            potential_target_cols = df.select_dtypes(include=np.number).columns.tolist()

            if not potential_target_cols:
                st.error("‚õî Kh√¥ng t√¨m th·∫•y c·ªôt s·ªë n√†o trong d·ªØ li·ªáu ƒë·ªÉ l√†m bi·∫øn m·ª•c ti√™u (Target) cho m√¥ h√¨nh h·ªìi quy.")
                # st.stop() # Kh√¥ng d·ª´ng h·∫≥n, cho ph√©p user quay l·∫°i t·∫£i file kh√°c
            else:
                # Kh√¥i ph·ª•c l·ª±a ch·ªçn c≈© n·∫øu c√≥
                target_index = 0
                if st.session_state.target_column and st.session_state.target_column in potential_target_cols:
                    target_index = potential_target_cols.index(st.session_state.target_column)

                selected_target = st.selectbox(
                    "üéØ Ch·ªçn c·ªôt m·ª•c ti√™u (Target - ph·∫£i l√† s·ªë):",
                     potential_target_cols,
                     index=target_index,
                     key="target_select"
                 )
                available_features = [col for col in all_columns if col != selected_target]

                # Kh√¥i ph·ª•c l·ª±a ch·ªçn feature c≈© n·∫øu c√≥ (c·∫£ s·ªë v√† category)
                default_features = []
                if st.session_state.numeric_cols_original or st.session_state.categorical_cols_original:
                     default_features = [f for f in (st.session_state.numeric_cols_original or []) + (st.session_state.categorical_cols_original or []) if f in available_features]
                else: # N·∫øu ch∆∞a c√≥ g√¨ th√¨ m·∫∑c ƒë·ªãnh ch·ªçn t·∫•t c·∫£ tr·ª´ target
                     default_features = available_features


                selected_features_original = st.multiselect(
                    "‚ú® Ch·ªçn c√°c c·ªôt ƒë·∫∑c tr∆∞ng (Features):",
                    available_features,
                    default=default_features,
                    key="feature_select"
                )

        with col2_setup:
            st.markdown("#### <i class='fas fa-robot'></i> Thu·∫≠t to√°n & Tham s·ªë", unsafe_allow_html=True)
            model_options = ["Linear Regression", "Random Forest Regressor", "Support Vector Regressor (SVR)"]
            selected_model_name = st.selectbox("ü§ñ Ch·ªçn thu·∫≠t to√°n:", model_options, key="model_select")

            # S·ª≠ d·ª•ng expander cho si√™u tham s·ªë
            with st.expander(f"üõ†Ô∏è Tinh ch·ªânh si√™u tham s·ªë cho {selected_model_name}", expanded=False):
                params = {}
                if selected_model_name == "Random Forest Regressor":
                    params['n_estimators'] = st.slider("S·ªë c√¢y (n_estimators):", 10, 1000, 100, 10, key="rf_n_estimators", help="S·ªë l∆∞·ª£ng c√¢y trong r·ª´ng.") # Gi·∫£m min
                    max_depth_input = st.number_input("ƒê·ªô s√¢u t·ªëi ƒëa (max_depth, 0=kh√¥ng gi·ªõi h·∫°n):", min_value=0, value=0, step=1, key="rf_max_depth", help="ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa m·ªói c√¢y. 0 nghƒ©a l√† kh√¥ng gi·ªõi h·∫°n.")
                    params['max_depth'] = None if max_depth_input == 0 else max_depth_input
                elif selected_model_name == "Support Vector Regressor (SVR)":
                    params['C'] = st.slider("Tham s·ªë C (Regularization):", 0.01, 100.0, 1.0, 0.01, format="%.2f", key="svr_c", help="Ngh·ªãch ƒë·∫£o c·ªßa c∆∞·ªùng ƒë·ªô ƒëi·ªÅu chu·∫©n. Gi√° tr·ªã nh·ªè h∆°n t∆∞∆°ng ·ª©ng v·ªõi ƒëi·ªÅu chu·∫©n m·∫°nh h∆°n.")
                    params['epsilon'] = st.slider("Epsilon:", 0.01, 1.0, 0.1, 0.01, format="%.2f", key="svr_epsilon", help="X√°c ƒë·ªãnh bi√™n ƒë·ªô m√† kh√¥ng c√≥ h√¨nh ph·∫°t n√†o ƒë∆∞·ª£c li√™n k·∫øt trong h√†m m·∫•t m√°t.")
                    params['kernel'] = st.radio("Kernel:", ['rbf', 'linear', 'poly', 'sigmoid'], index=0, key="svr_kernel", horizontal=True, help="Lo·∫°i kernel ƒë∆∞·ª£c s·ª≠ d·ª•ng trong thu·∫≠t to√°n.")
                else:
                    st.info("Linear Regression c∆° b·∫£n kh√¥ng y√™u c·∫ßu tinh ch·ªânh si√™u tham s·ªë ph·ª©c t·∫°p.")

        st.markdown("---")

        # ƒê·∫∑t n√∫t hu·∫•n luy·ªán ·ªü gi·ªØa
        col_button_spacer1, col_button, col_button_spacer2 = st.columns([1, 1.5, 1])
        with col_button:
            if st.button("‚ö°Ô∏è Hu·∫•n luy·ªán M√¥ h√¨nh Ngay! ‚ö°Ô∏è", key="train_button_main", use_container_width=True):
                # Reset l·ªói c≈© tr∆∞·ªõc khi hu·∫•n luy·ªán
                st.session_state.preprocessing_error = None
                st.session_state.training_error = None
                st.session_state.model = None # Reset model c≈©

                if not selected_features_original:
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt Feature.")
                elif not selected_target:
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn Target.")
                else:
                    with st.spinner("‚öôÔ∏è ƒêang ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu..."):
                        # G·ªçi h√†m ti·ªÅn x·ª≠ l√Ω ƒë√£ s·ª≠a
                        preprocess_result = preprocess_data(df.copy(), selected_target, selected_features_original)

                        # Ki·ªÉm tra k·∫øt qu·∫£ ti·ªÅn x·ª≠ l√Ω
                        if isinstance(preprocess_result[0], str): # N·∫øu ph·∫ßn t·ª≠ ƒë·∫ßu l√† string -> l·ªói
                            st.session_state.preprocessing_error = preprocess_result[0]
                            st.error(f"L·ªói ti·ªÅn x·ª≠ l√Ω: {st.session_state.preprocessing_error}")
                             # ƒê·∫£m b·∫£o reset c√°c state kh√°c n·∫øu l·ªói x·∫£y ra ·ªü ƒë√¢y
                            st.session_state.scaler = None
                            st.session_state.numeric_imputer = None
                            st.session_state.categorical_imputer = None
                            st.session_state.feature_names_processed = None
                            st.session_state.numeric_cols_original = None
                            st.session_state.categorical_cols_original = None
                        else:
                            # Gi·∫£i n√©n k·∫øt qu·∫£ th√†nh c√¥ng
                            X, y, feature_names_proc, scaler, num_imputer, cat_imputer, num_orig, cat_orig = preprocess_result
                            st.session_state.preprocessing_error = None # Kh√¥ng c√≥ l·ªói

                            # L∆∞u c√°c th√†nh ph·∫ßn ƒë√£ FIT v√†o session_state
                            st.session_state.scaler = scaler
                            st.session_state.numeric_imputer = num_imputer # ƒê√£ ƒë∆∞·ª£c fit
                            st.session_state.categorical_imputer = cat_imputer # ƒê√£ ƒë∆∞·ª£c fit
                            st.session_state.feature_names_processed = feature_names_proc
                            st.session_state.target_column = selected_target
                            st.session_state.numeric_cols_original = num_orig
                            st.session_state.categorical_cols_original = cat_orig

                            # Chia d·ªØ li·ªáu
                            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) # TƒÉng test size
                            st.write(f"üìä K√≠ch th∆∞·ªõc t·∫≠p Train: {X_train.shape} | Test: {X_test.shape}")
                            st.write(f"üìà S·ªë l∆∞·ª£ng features sau ti·ªÅn x·ª≠ l√Ω: {X_train.shape[1]}")
                            # st.write(f"T√™n features sau x·ª≠ l√Ω: {st.session_state.feature_names_processed}") # Debug

                    # Ch·ªâ hu·∫•n luy·ªán n·∫øu ti·ªÅn x·ª≠ l√Ω th√†nh c√¥ng
                    if st.session_state.preprocessing_error is None:
                         # Hu·∫•n luy·ªán (h√†m n√†y ƒë√£ c√≥ spinner v√† progress)
                         model, training_err = train_model(X_train, y_train, selected_model_name, params)

                         st.session_state.training_error = training_err
                         st.session_state.model = model # L∆∞u model (c√≥ th·ªÉ l√† None n·∫øu l·ªói)

                         if st.session_state.model:
                             # st.success(f"‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh {selected_model_name} th√†nh c√¥ng!")
                             st.balloons() # Th√™m hi·ªáu ·ª©ng b√≥ng bay khi th√†nh c√¥ng!

                             st.markdown(f"#### <i class='fas fa-check-circle'></i> K·∫øt qu·∫£ ƒê√°nh gi√° tr√™n t·∫≠p Test ({selected_model_name})", unsafe_allow_html=True)
                             y_pred = st.session_state.model.predict(X_test)
                             mse = mean_squared_error(y_test, y_pred)
                             r2 = r2_score(y_test, y_pred)
                             rmse = np.sqrt(mse)

                             res_col1, res_col2 = st.columns(2)
                             res_col1.metric(
                                 label="üìâ RMSE (Root Mean Squared Error)",
                                 value=f"{rmse:.4f}",
                                 delta=None,
                                 help="CƒÉn b·∫≠c hai c·ªßa MSE, c√πng ƒë∆°n v·ªã v·ªõi target. C√†ng nh·ªè c√†ng t·ªët."
                             )
                             res_col2.metric(
                                 label="üìà R¬≤ Score",
                                 value=f"{r2:.4f}",
                                 help="H·ªá s·ªë x√°c ƒë·ªãnh, ƒëo l∆∞·ªùng m·ª©c ƒë·ªô bi·∫øn thi√™n c·ªßa target ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi m√¥ h√¨nh. C√†ng g·∫ßn 1 c√†ng t·ªët (t·ªëi ƒëa l√† 1)."
                             )

                             # Plotly so s√°nh th·ª±c t·∫ø vs d·ª± ƒëo√°n
                             with st.expander("üîç Xem bi·ªÉu ƒë·ªì so s√°nh Th·ª±c t·∫ø vs. D·ª± ƒëo√°n", expanded=True): # M·ªü r·ªông m·∫∑c ƒë·ªãnh
                                 comparison_df = pd.DataFrame({'Th·ª±c t·∫ø': y_test, 'D·ª± ƒëo√°n': y_pred})
                                 # Gi·ªõi h·∫°n s·ªë ƒëi·ªÉm v·∫Ω n·∫øu qu√° nhi·ªÅu ƒë·ªÉ tr√°nh ch·∫≠m
                                 if len(comparison_df) > 1000:
                                      comparison_df_sample = comparison_df.sample(1000, random_state=42)
                                      plot_title = '<b>So s√°nh Gi√° tr·ªã Th·ª±c t·∫ø v√† D·ª± ƒëo√°n (1000 ƒëi·ªÉm m·∫´u)</b>'
                                 else:
                                      comparison_df_sample = comparison_df
                                      plot_title = '<b>So s√°nh Gi√° tr·ªã Th·ª±c t·∫ø v√† D·ª± ƒëo√°n</b>'

                                 fig_comp = px.scatter(
                                     comparison_df_sample, x='Th·ª±c t·∫ø', y='D·ª± ƒëo√°n',
                                     title=plot_title,
                                     opacity=0.6,
                                     trendline='ols', # Th√™m ƒë∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh OLS
                                     trendline_color_override='red',
                                     labels={'Th·ª±c t·∫ø': f'Gi√° tr·ªã Th·ª±c t·∫ø ({selected_target})', 'D·ª± ƒëo√°n': f'Gi√° tr·ªã D·ª± ƒëo√°n ({selected_target})'}
                                 )
                                 # Th√™m ƒë∆∞·ªùng y=x ƒë·ªÉ so s√°nh
                                 min_val = min(y_test.min(), y_pred.min())
                                 max_val = max(y_test.max(), y_pred.max())
                                 fig_comp.add_shape(type='line', line=dict(dash='dash', color='white', width=2),
                                                    x0=min_val, y0=min_val, x1=max_val, y1=max_val)
                                 fig_comp.update_layout(title_x=0.5)
                                 st.plotly_chart(fig_comp, use_container_width=True)
                                 st.caption("ƒê∆∞·ªùng n√©t ƒë·ª©t m√†u tr·∫Øng l√† ƒë∆∞·ªùng y=x (d·ª± ƒëo√°n ho√†n h·∫£o). ƒê∆∞·ªùng m√†u ƒë·ªè l√† ƒë∆∞·ªùng xu h∆∞·ªõng OLS.")

                         # else: # L·ªói ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã trong h√†m train_model
                         #     # st.error("‚ùå Hu·∫•n luy·ªán th·∫•t b·∫°i. Vui l√≤ng ki·ªÉm tra th√¥ng b√°o l·ªói ·ªü tr√™n.")
                         #     pass

    elif st.session_state.df is None and not st.session_state.df_loaded: # N·∫øu ch∆∞a t·∫£i file th√†nh c√¥ng
         st.warning("‚òùÔ∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu h·ª£p l·ªá ·ªü Tab 1 tr∆∞·ªõc khi hu·∫•n luy·ªán.")
    # Kh√¥ng c·∫ßn else n·∫øu df_loaded=True nh∆∞ng df=None (ƒë√£ c√≥ l·ªói ·ªü Tab 1)


# == Tab 3: D·ª± ƒëo√°n ==
with tab3:
    st.markdown("### <i class='fas fa-hat-wizard'></i> 4. D·ª± ƒëo√°n Gi√° tr·ªã M·ªõi", unsafe_allow_html=True)

    # Ch·ªâ hi·ªÉn th·ªã form n·∫øu ƒë√£ hu·∫•n luy·ªán model th√†nh c√¥ng v√† c√≥ ƒë·ªß th√¥ng tin c·∫ßn thi·∫øt
    if (st.session_state.model is not None and
        st.session_state.scaler is not None and
        st.session_state.numeric_imputer is not None and # C·∫ßn imputer
        st.session_state.categorical_imputer is not None and # C·∫ßn imputer
        st.session_state.feature_names_processed is not None and
        st.session_state.numeric_cols_original is not None and
        st.session_state.categorical_cols_original is not None):

        required_original_features = st.session_state.numeric_cols_original + st.session_state.categorical_cols_original
        st.info(f"üëá Nh·∫≠p gi√° tr·ªã cho c√°c ƒë·∫∑c tr∆∞ng **g·ªëc** sau ƒë√¢y ƒë·ªÉ d·ª± ƒëo√°n **{st.session_state.target_column}**:")
        # st.write(f"({', '.join(required_original_features)})") # Ghi ch√∫ c√°c c·ªôt c·∫ßn nh·∫≠p

        with st.form(key="prediction_form_styled"):
            input_data_raw = {} # L∆∞u gi√° tr·ªã ng∆∞·ªùi d√πng nh·∫≠p
            input_cols_for_df = {} # D√πng ƒë·ªÉ t·∫°o DataFrame ƒë·∫ßu v√†o

            # Chia c·ªôt linh ho·∫°t h∆°n cho c√°c widget input
            total_orig_cols = len(required_original_features)
            num_widget_cols = min(total_orig_cols, 3) # T·ªëi ƒëa 3 c·ªôt input tr√™n 1 h√†ng
            if num_widget_cols <= 0:
                 st.warning("Kh√¥ng c√≥ feature n√†o ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ hu·∫•n luy·ªán.")
            else:
                widget_cols = st.columns(num_widget_cols)
                current_col_index = 0

                # Input s·ªë
                for col in st.session_state.numeric_cols_original:
                    with widget_cols[current_col_index % num_widget_cols]:
                         # S·ª≠ d·ª•ng gi√° tr·ªã trung b√¨nh t·ª´ imputer l√†m gi√° tr·ªã m·∫∑c ƒë·ªãnh
                         default_val_num = 0.0
                         try:
                             # T√¨m index c·ªßa c·ªôt trong imputer
                              col_idx_imputer = st.session_state.numeric_cols_original.index(col)
                              if st.session_state.numeric_imputer and hasattr(st.session_state.numeric_imputer, 'statistics_'):
                                  default_val_num = float(st.session_state.numeric_imputer.statistics_[col_idx_imputer])
                         except Exception: # B·ªè qua l·ªói n·∫øu kh√¥ng t√¨m th·∫•y ho·∫∑c imputer ch∆∞a fit
                              pass
                         input_data_raw[col] = st.number_input(
                             f"{col} (S·ªë)",
                             value=default_val_num,
                             format="%.5f", # Cho ph√©p nh·∫≠p s·ªë th·∫≠p ph√¢n
                             key=f"input_{col}",
                             help=f"Nh·∫≠p gi√° tr·ªã s·ªë cho {col}"
                         )
                         input_cols_for_df[col] = [input_data_raw[col]] # ƒê·∫∑t trong list ƒë·ªÉ t·∫°o df
                    current_col_index += 1

                # Input category
                df_predict_source = st.session_state.df # L·∫•y df g·ªëc ƒë·ªÉ t√¨m unique values
                for col in st.session_state.categorical_cols_original:
                    with widget_cols[current_col_index % num_widget_cols]:
                         unique_vals = [""] + sorted(df_predict_source[col].dropna().unique().astype(str).tolist())
                         # default_val_cat = "" # M·∫∑c ƒë·ªãnh tr·ªëng
                         # L·∫•y gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t l√†m m·∫∑c ƒë·ªãnh n·∫øu c√≥ th·ªÉ
                         default_val_cat = ""
                         try:
                             col_idx_cat_imputer = st.session_state.categorical_cols_original.index(col)
                             if st.session_state.categorical_imputer and hasattr(st.session_state.categorical_imputer, 'statistics_'):
                                  imputed_val = st.session_state.categorical_imputer.statistics_[col_idx_cat_imputer]
                                  if imputed_val in unique_vals: # Ch·ªâ d√πng n·∫øu gi√° tr·ªã ƒë√≥ c√≥ trong list
                                       default_val_cat = imputed_val
                         except Exception:
                              pass

                         input_data_raw[col] = st.selectbox(
                             f"{col} (Category)",
                             options=unique_vals,
                             index=unique_vals.index(default_val_cat) if default_val_cat in unique_vals else 0, # Ch·ªçn m·∫∑c ƒë·ªãnh n·∫øu t√¨m th·∫•y, n·∫øu kh√¥ng ch·ªçn ""
                             key=f"input_{col}",
                             help=f"Ch·ªçn m·ªôt gi√° tr·ªã cho {col}. ƒê·ªÉ tr·ªëng n·∫øu kh√¥ng bi·∫øt (s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω)."
                         )
                         # N·∫øu ng∆∞·ªùi d√πng ch·ªçn "", coi nh∆∞ l√† NaN ƒë·ªÉ imputer x·ª≠ l√Ω
                         input_cols_for_df[col] = [np.nan if input_data_raw[col] == "" else input_data_raw[col]]
                    current_col_index += 1

                # --- N√∫t Submit ---
                submitted = st.form_submit_button("üîÆ D·ª± ƒëo√°n Ngay!", use_container_width=True)

                if submitted:
                    st.session_state.last_prediction = None # Reset d·ª± ƒëo√°n c≈©
                    with st.spinner("üß† ƒêang x·ª≠ l√Ω v√† d·ª± ƒëo√°n..."):
                        try:
                            # 1. T·∫°o DataFrame t·ª´ input (ƒë√∫ng th·ª© t·ª± c·ªôt g·ªëc)
                            input_df = pd.DataFrame(input_cols_for_df, index=[0])
                            input_df = input_df[required_original_features] # ƒê·∫£m b·∫£o ƒë√∫ng th·ª© t·ª±

                            # 2. X·ª≠ l√Ω NaN b·∫±ng imputer ƒë√£ fit (kh√¥ng c·∫ßn fit l·∫°i)
                            numeric_features_predict = [col for col in st.session_state.numeric_cols_original if col in input_df.columns]
                            categorical_features_predict = [col for col in st.session_state.categorical_cols_original if col in input_df.columns]

                            if numeric_features_predict and st.session_state.numeric_imputer:
                                input_df[numeric_features_predict] = st.session_state.numeric_imputer.transform(input_df[numeric_features_predict])
                            if categorical_features_predict and st.session_state.categorical_imputer:
                                input_df[categorical_features_predict] = st.session_state.categorical_imputer.transform(input_df[categorical_features_predict])

                            # 3. One-Hot Encoding (ph·∫£i gi·ªëng h·ªát l√∫c train)
                            input_df_processed = pd.get_dummies(input_df, columns=st.session_state.categorical_cols_original, drop_first=True)

                            # 4. CƒÉn ch·ªânh c·ªôt v·ªõi feature_names_processed (th√™m c·ªôt thi·∫øu, x√≥a c·ªôt th·ª´a)
                            # C√°c c·ªôt c√≥ trong t·∫≠p train nh∆∞ng thi·∫øu trong input -> th√™m v√†o v√† g√°n gi√° tr·ªã 0 (v√¨ ƒë√£ drop_first=True)
                            missing_cols = set(st.session_state.feature_names_processed) - set(input_df_processed.columns)
                            for c in missing_cols:
                                input_df_processed[c] = 0
                            # C√°c c·ªôt c√≥ trong input nh∆∞ng kh√¥ng c√≥ trong t·∫≠p train -> x√≥a ƒëi
                            extra_cols = set(input_df_processed.columns) - set(st.session_state.feature_names_processed)
                            input_df_processed = input_df_processed.drop(columns=list(extra_cols))

                            # ƒê·∫£m b·∫£o th·ª© t·ª± c·ªôt gi·ªëng h·ªát l√∫c train
                            input_df_processed = input_df_processed[st.session_state.feature_names_processed]

                            # 5. Chu·∫©n h√≥a b·∫±ng scaler ƒë√£ fit
                            input_scaled = st.session_state.scaler.transform(input_df_processed)

                            # 6. D·ª± ƒëo√°n
                            prediction = st.session_state.model.predict(input_scaled)
                            st.session_state.last_prediction = prediction[0] # L·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n

                            # 7. Hi·ªÉn th·ªã k·∫øt qu·∫£
                            st.success(f"‚ú® **K·∫øt qu·∫£ D·ª± ƒëo√°n cho {st.session_state.target_column}:**")
                            # S·ª≠ d·ª•ng metric ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n
                            st.metric(label=f"Gi√° tr·ªã d·ª± ƒëo√°n ({st.session_state.target_column})", value=f"{st.session_state.last_prediction:,.2f}") # ƒê·ªãnh d·∫°ng s·ªë

                        except Exception as e:
                            st.error(f"L·ªói khi th·ª±c hi·ªán d·ª± ƒëo√°n: {e}")
                            st.exception(e) # In traceback ƒë·ªÉ debug

    elif st.session_state.model is None and st.session_state.df_loaded: # N·∫øu ƒë√£ load data nh∆∞ng ch∆∞a train
         st.warning("‚è≥ Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh ·ªü Tab 2 tr∆∞·ªõc khi d·ª± ƒëo√°n.")
    elif not st.session_state.df_loaded: # N·∫øu ch∆∞a load data
         st.warning("‚òùÔ∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu ·ªü Tab 1 v√† hu·∫•n luy·ªán m√¥ h√¨nh ·ªü Tab 2 tr∆∞·ªõc.")

    # Hi·ªÉn th·ªã l·∫°i k·∫øt qu·∫£ d·ª± ƒëo√°n cu·ªëi c√πng n·∫øu c√≥ (ngo√†i form)
    # if st.session_state.last_prediction is not None and not submitted: # Ch·ªâ hi·ªÉn th·ªã n·∫øu kh√¥ng ph·∫£i v·ª´a submit
    #      st.info(f"K·∫øt qu·∫£ d·ª± ƒëo√°n l·∫ßn cu·ªëi: {st.session_state.last_prediction:,.2f}")
